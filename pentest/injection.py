import json
from celery.decorators import task
from .models import *
import os,requests
import re
from urllib.parse import urlparse
from lib.config_json import *
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))




#过滤重复的数据包
#@task
def filter():
    datas = proxy_data.objects.all()
    for data in datas:
        if data.method == 'GET':
            tmp = ''
            try:
                url = re.match('\S+\?', data.url).group()
                parms = data.url.split(url)[-1].split('&')
                for parm in parms:
                    tmp =  parm.split('=')[0]+ ','+tmp
                record = len(filter_data.objects.filter(url=data.url.split('?')[0]))
                if record != 0:
                    parm = filter_data.objects.get(url=data.url.split('?')[0]).parm
                    tmp_list = tmp.split(',')
                    parm_list = parm.split(',')
                    Union = list(set(tmp_list).union(set(parm_list))) #列表的并集
                    if len(Union) != len(parm_list):
                        packet = data.method + ' ' + data.url + ' ' + data.http_version + '\n' + data.request_headers
                        filter_data.objects.create(url=data.url,data_packet=packet,parm=tmp)
                else:
                    packet = data.method + ' ' + data.url + ' ' + data.http_version + '\n' + data.request_headers
                    filter_data.objects.create(
                        host=data.host,
                        url=data.url.split('?')[0],
                        data_packet=packet,
                        parm=tmp)
            except AttributeError:
                pass

        elif data.method == 'POST':
            url = data.url
            record = len(filter_data.objects.filter(url=url))
            packet = data.method + ' ' + data.url + ' ' + data.http_version + '\n' + data.request_headers +'\n\n'+data.request_content
            post_data = data.request_content
            json_data = re.findall('^{\S+}$', post_data)
            if record ==0: #如果数据库没有记录，写入数据
                if len(data.request_content) >0: #post数据为0
                    if len(json_data) > 0:   #post为json方式
                        json_list = re.findall('"(.*?)":.*?,',json_data[0])
                        json_str = ",".join(json_list)
                        filter_data.objects.create(host=data.host,url=url,data_packet=packet,parm=json_str)
                    else: #post为正常方式，loginDate=2017-10-25&searchVal=&loginStatus=all&pageIndex=1&pageSize=10
                        parm = ''
                        parms = data.request_content.split('&')
                        for i in parms:
                            parm = i.split('=')[0]+','+parm
                        filter_data.objects.create(host=data.host,url=url,parm=parm,data_packet=packet)
                else:
                    filter_data.objects.create(host=data.host,url=url, parm='', data_packet=packet)
            else: #数据库有记录，如果记录重复，忽略
                if len(data.request_content) > 0:  # post数据为0
                    if len(json_data) > 0:   #post为json方式
                        json_list = re.findall('"(.*?)":.*?,',json_data[0])
                        data_list = filter_data.objects.filter(url=url)[0].parm.split(',')
                        Union = list(set(json_list).union(set(data_list)))  # 列表的并集
                        if len(Union) != len(data_list):
                            filter_data.objects.create(host=data.host,url=data.url, data_packet=packet, parm=",".join(json_list))

                    else: #post为正常方式，loginDate=2017-10-25&searchVal=&loginStatus=all&pageIndex=1&pageSize=10
                        parm = ''
                        parms = data.request_content.split('&')
                        data_list = filter_data.objects.filter(url=url)[0].parm.split(',')
                        for i in parms:
                            parm = i.split('=')[0]+','+parm
                        parm_list = parm.split(',')
                        Union = list(set(parm_list).union(set(data_list)))  # 列表的并集
                        if len(Union) != len(data_list):
                            filter_data.objects.create(host=data.host,url=data.url, data_packet=packet, parm=parm)

class autosqli(object):
    def __init__(self):
        self.headers = {'Content-Type': 'application/json'}
        self.data = {}


    def new_taskid(self):
        results = filter_data.objects.all()
        for result in results:
            if len(result.taskid) == 0:
                url = SQLMAP_API_SERVER + "/task/new"
                taskid = requests.get(url).json()['taskid']
                options = {
                    'paramExclude': SQLMAP_PARMEXCLUDE,
                    'threads': SQLMAP_THREADS,
                    'level': SQLMAP_LEVEL,
                    'risk': SQLMAP_RISK,
                    'dbms': SQLMAP_DBMS,
                    'requestFile': SQLMAP_REQUESTFILE_PATH+taskid,
                    'flushSession': True,
                    'retries':SQLMAP_RETRIES,
                }
                self.set_options(taskid,options)
                result.taskid = taskid
                result.save()
                try:
                    fp = open(SQLMAP_REQUESTFILE_PATH + taskid, 'w+')
                    fp.writelines(str(result.data_packet) + '\n')
                    fp.close()
                except UnicodeEncodeError:
                    pass



    def del_taskid(self):
        url = SQLMAP_API_SERVER + '/task/' + self.taskid + '/delete'

    def set_options(self,taskid,options):
        url = SQLMAP_API_SERVER + "/option/" + taskid + "/set"
        data = json.dumps(options)
        r = requests.post(url, data=data, headers=self.headers)


    def list_options(self):
        url = self.server + '/option/' + self.taskid + '/list'

    def get_options(self):
        url = self.server + '/option/' + self.taskid + '/get'

    def start_scan(self):
        results = filter_data.objects.all()
        for result in results:
            if result.status == '0' or result.status=="":
                taskid = result.taskid
                #host = re.findall("(http://|https://)(.*?)/",result.url)[0][1]
                host=urlparse(result.url).netloc
                inject_data.objects.create(taskid=taskid,host_id=target_info.objects.get_or_create(host=host)[0].id)
                url = SQLMAP_API_SERVER + "/scan/" + taskid + "/start"
                t = requests.post(url, data=json.dumps(self.data), headers=self.headers)
                result.status = '1'
                result.save()


    def stop_scan(self):
        url = self.server + "/scan/" + self.taskid + "/stop"

    def status_scan(self):
        url = self.server + '/scan/' + self.taskid + '/status'

    def kill_scan(self):
        url = self.server + '/scan/' + self.taskid + '/kill'

    def scan_log(self,taskid):
        url = SQLMAP_API_SERVER + '/scan/' + taskid + '/log'
        r = requests.get(url=url, headers=self.headers)
        logs = r.json()['log']
        log = ""
        for i in logs:
            log = log + "[" + i['level'] + "]" + "[" + i['time'] + "]" + i['message'] + "\n"
        sqlmap_log.objects.create(taskid=taskid,log=log)
        if logs[-1]['level'] == "CRITICAL" and "connection timed out to the target URL" in logs[-1]['message']:
            return "连接超时"
        elif logs[-1]['level'] == 'INFO':
            return "成功"
        elif logs[-1]['level'] == "CRITICAL" and "all tested parameters do not appear to be injectable" in logs[-1]['message']:
            return "失败"
        else:
            return ""


    def runstatus(self):
        results = inject_data.objects.all()
        for result in results:
            if result.status == '0':
                url = SQLMAP_API_SERVER + '/scan/' + result.taskid + '/status'
                run_status = requests.get(url).json()['status']
                print(run_status)
                parameter = ''
                if run_status == 'terminated':

                    #SQLMAP结束的状态
                    log_staus = self.scan_log(result.taskid)

                    if result.status == '0':
                        url = SQLMAP_API_SERVER + '/scan/' + result.taskid + '/data'
                        data = requests.get(url).json()['data']
                        if len(data) > 0 :
                            status = data[0]['status']
                            url1 = data[0]['value']['url']
                            for i in data[1]['value']:
                                dbms = i['dbms']
                                parameter = i['parameter'] +','+parameter
                            result.packet = filter_data.objects.get(taskid=result.taskid).data_packet
                            result.url =url1
                            result.dbms= dbms
                            result.vul_info = '漏洞存在'
                            result.parameter = parameter
                            result.status = status
                            result.run_status = run_status
                            result.log_status = log_staus
                            result.save()
                        else:
                            result.status = '1'
                            result.vul_info = '漏洞不存在'
                            result.run_status = run_status
                            result.log_status = log_staus
                            result.save()
                elif run_status == 'running':
                    result.run_status = run_status
                    result.save()

